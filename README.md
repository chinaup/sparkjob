<br>爬取51job上的spark工作数据，使用spark进行分析以及可视化</br>
<br>一、运行sprider_job.py文件爬取spark工作信息保存为jobinfo.csv</br>
<br>二、分别运行jobcount.scala、moneycount.scala、placecount.scala三个文件获得分析后的数据</br>
<br>三、使用BDP可视化结果如下:</br>
![Image text](https://github.com/chinaup/sparkjob/blob/master/sparkjob/picture/%E5%B7%A5%E4%BD%9C%E6%95%B0%E7%9B%AE%E6%9F%B1%E7%8A%B6%E5%9B%BE.png)
