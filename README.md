爬取51job上的spark工作数据，使用spark进行分析以及可视化
======
一、运行sprider_job.py文件爬取spark工作信息保存为jobinfo.csv

二、分别运行jobcount.scala、moneycount.scala、placecount.scala三个文件获得分析后的数据

三、使用BDP可视化结果如下:

![Image text](https://github.com/chinaup/sparkjob/blob/master/sparkjob/picture/%E5%B7%A5%E4%BD%9C%E6%95%B0%E7%9B%AE%E6%9F%B1%E7%8A%B6%E5%9B%BE.png)
![Image text](https://github.com/chinaup/sparkjob/blob/master/sparkjob/picture/%E5%B7%A5%E4%BD%9C%E6%95%B0%E7%9B%AE%E6%9D%A1%E5%BD%A2%E5%9B%BE.png)
![Image text](https://github.com/chinaup/sparkjob/blob/master/sparkjob/picture/%E5%B7%A5%E4%BD%9C%E6%95%B0%E7%9B%AE%E9%A5%BC%E7%8A%B6%E5%9B%BE.png)
![Image text](https://github.com/chinaup/sparkjob/blob/master/sparkjob/picture/%E5%B7%A5%E4%BD%9C%E5%8C%BA%E5%9F%9F%E5%9B%BE.png
)
![Image text](https://github.com/chinaup/sparkjob/blob/master/sparkjob/picture/%E5%B7%A5%E8%B5%84%E5%8C%BA%E9%97%B4%E6%9F%B1%E7%8A%B6%E5%9B%BE.png)
